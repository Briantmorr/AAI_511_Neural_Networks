{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kerastuner as kt\n",
    "import tensorflow as tf\n",
    "import music21\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/preprocessed_data_with_midi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded_notes'] = df['encoded_notes'].apply(lambda x: ast.literal_eval(x))\n",
    "df['encoded_chords'] = df['encoded_chords'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More preprocessing. Zero pad arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 10000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midi_file</th>\n",
       "      <th>composer</th>\n",
       "      <th>path</th>\n",
       "      <th>notes</th>\n",
       "      <th>chords</th>\n",
       "      <th>tempos</th>\n",
       "      <th>encoded_notes</th>\n",
       "      <th>encoded_chords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bwv0997 Partita for Lute 1mov.mid</td>\n",
       "      <td>Bach</td>\n",
       "      <td>./data/Bach/</td>\n",
       "      <td>['C3', 'C5', 'D5', 'E-5', 'G5', 'B5', 'C6', 'B...</td>\n",
       "      <td>['9.10', '7.8', '6.9', '0.3', '0.6', '2', '7.1...</td>\n",
       "      <td>[80, 80, 60, 60, 120, 120, 60, 60, 80, 80]</td>\n",
       "      <td>[48, 72, 74, 75, 79, 83, 84, 46, 84, 44, 72, 7...</td>\n",
       "      <td>[9, 7, 6, 0, 0, 2, 7, 2, 3, 7, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bwv0535 Prelude and Fugue.mid</td>\n",
       "      <td>Bach</td>\n",
       "      <td>./data/Bach/</td>\n",
       "      <td>['G3', 'D3', 'B-2', 'D3', 'G2', 'A3', 'B-3', '...</td>\n",
       "      <td>['2.7', '0.6', '7.10', '9', '7.10', '7.11', '7...</td>\n",
       "      <td>[80, 80, 80, 50, 50, 50, 65, 65, 65, 60, 60, 6...</td>\n",
       "      <td>[55, 50, 46, 50, 43, 57, 58, 60, 58, 55, 50, 5...</td>\n",
       "      <td>[2, 0, 7, 9, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bwv0806 English Suite n1 05mov.mid</td>\n",
       "      <td>Bach</td>\n",
       "      <td>./data/Bach/</td>\n",
       "      <td>['A4', 'A4', 'A2', 'E4', 'C#4', 'A3', 'G#3', '...</td>\n",
       "      <td>['5.6', '1.2', '11.4', '1.2', '4.6', '2.4', '4...</td>\n",
       "      <td>[144, 144]</td>\n",
       "      <td>[69, 69, 45, 64, 61, 57, 56, 54, 52, 54, 50, 6...</td>\n",
       "      <td>[5, 1, 11, 1, 4, 2, 4, 4, 4, 2, 8, 1, 5, 1, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bwv0998 Prelude Fugue Allegro for Lute 3mov.mid</td>\n",
       "      <td>Bach</td>\n",
       "      <td>./data/Bach/</td>\n",
       "      <td>['E-2', 'E-4', 'D4', 'C4', 'B-3', 'G#3', 'G3',...</td>\n",
       "      <td>['2.5', '7.8', '7.10', '4.7', '5.8']</td>\n",
       "      <td>[100, 100, 100, 8, 8, 8]</td>\n",
       "      <td>[39, 63, 62, 60, 58, 56, 55, 51, 60, 58, 56, 5...</td>\n",
       "      <td>[2, 7, 7, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jesu Joy of Man Desiring.mid</td>\n",
       "      <td>Bach</td>\n",
       "      <td>./data/Bach/</td>\n",
       "      <td>['G2', 'G1', 'G1', 'G4', 'G4', 'A4', 'A4', 'B4...</td>\n",
       "      <td>['11.0', '11.0', '11.0', '11.0', '11.0', '11.0...</td>\n",
       "      <td>[65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 6...</td>\n",
       "      <td>[43, 31, 31, 67, 67, 69, 69, 71, 71, 67, 62, 5...</td>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 11, 9, 9, 9, 9, 9, 9,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         midi_file composer          path  \\\n",
       "0                Bwv0997 Partita for Lute 1mov.mid     Bach  ./data/Bach/   \n",
       "1                    Bwv0535 Prelude and Fugue.mid     Bach  ./data/Bach/   \n",
       "2               Bwv0806 English Suite n1 05mov.mid     Bach  ./data/Bach/   \n",
       "3  Bwv0998 Prelude Fugue Allegro for Lute 3mov.mid     Bach  ./data/Bach/   \n",
       "4                     Jesu Joy of Man Desiring.mid     Bach  ./data/Bach/   \n",
       "\n",
       "                                               notes  \\\n",
       "0  ['C3', 'C5', 'D5', 'E-5', 'G5', 'B5', 'C6', 'B...   \n",
       "1  ['G3', 'D3', 'B-2', 'D3', 'G2', 'A3', 'B-3', '...   \n",
       "2  ['A4', 'A4', 'A2', 'E4', 'C#4', 'A3', 'G#3', '...   \n",
       "3  ['E-2', 'E-4', 'D4', 'C4', 'B-3', 'G#3', 'G3',...   \n",
       "4  ['G2', 'G1', 'G1', 'G4', 'G4', 'A4', 'A4', 'B4...   \n",
       "\n",
       "                                              chords  \\\n",
       "0  ['9.10', '7.8', '6.9', '0.3', '0.6', '2', '7.1...   \n",
       "1  ['2.7', '0.6', '7.10', '9', '7.10', '7.11', '7...   \n",
       "2  ['5.6', '1.2', '11.4', '1.2', '4.6', '2.4', '4...   \n",
       "3               ['2.5', '7.8', '7.10', '4.7', '5.8']   \n",
       "4  ['11.0', '11.0', '11.0', '11.0', '11.0', '11.0...   \n",
       "\n",
       "                                              tempos  \\\n",
       "0         [80, 80, 60, 60, 120, 120, 60, 60, 80, 80]   \n",
       "1  [80, 80, 80, 50, 50, 50, 65, 65, 65, 60, 60, 6...   \n",
       "2                                         [144, 144]   \n",
       "3                           [100, 100, 100, 8, 8, 8]   \n",
       "4  [65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 6...   \n",
       "\n",
       "                                       encoded_notes  \\\n",
       "0  [48, 72, 74, 75, 79, 83, 84, 46, 84, 44, 72, 7...   \n",
       "1  [55, 50, 46, 50, 43, 57, 58, 60, 58, 55, 50, 5...   \n",
       "2  [69, 69, 45, 64, 61, 57, 56, 54, 52, 54, 50, 6...   \n",
       "3  [39, 63, 62, 60, 58, 56, 55, 51, 60, 58, 56, 5...   \n",
       "4  [43, 31, 31, 67, 67, 69, 69, 71, 71, 67, 62, 5...   \n",
       "\n",
       "                                      encoded_chords  \n",
       "0               [9, 7, 6, 0, 0, 2, 7, 2, 3, 7, 0, 0]  \n",
       "1  [2, 0, 7, 9, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "2  [5, 1, 11, 1, 4, 2, 4, 4, 4, 2, 8, 1, 5, 1, 11...  \n",
       "3                                    [2, 7, 7, 4, 5]  \n",
       "4  [11, 11, 11, 11, 11, 11, 11, 9, 9, 9, 9, 9, 9,...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_truncate_sequences(sequences, max_len=MAX_LEN):\n",
    "    return pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_notes = pad_truncate_sequences(df['encoded_notes'])\n",
    "X_chords = pad_truncate_sequences(df['encoded_chords'])\n",
    "# X_tempos = pad_truncate_sequences(df['tempos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((X_notes, X_chords), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1530, 10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['composer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X, y):\n",
    "    smote = SMOTE(random_state=42)  \n",
    "\n",
    "    num_samples, num_timesteps, num_features = X.shape\n",
    "    X_flatten = X.reshape(num_samples, -1)\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_smote, y_smote = smote.fit_resample(X_flatten, y)\n",
    "\n",
    "    print(pd.Series(y_smote).value_counts())\n",
    "    X_smote_reshaped = X_smote.reshape(X_smote.shape[0], num_timesteps, num_features)\n",
    "\n",
    "    return X_smote_reshaped, y_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_train, y_temp, y_train = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Need to apply smote to training before we convert to categorical\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_temp = to_categorical(y_temp, num_classes=num_classes)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1224, 10000, 2) (1224,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    753\n",
      "3    753\n",
      "2    753\n",
      "1    753\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3012, 10000, 2) (3012,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = cnn_model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CNNHyperModel.__init_subclass__() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCNNHyperModel\u001b[39;00m(kt\u001b[38;5;241m.\u001b[39mHyperModel, input_shape\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp):\n\u001b[1;32m      3\u001b[0m         model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "\u001b[0;31mTypeError\u001b[0m: CNNHyperModel.__init_subclass__() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "class CNNHyperModel(kt.HyperModel, input_shape=X_train.shape[1:]):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Int('filters_1', min_value=64, max_value=256, step=64),\n",
    "                        kernel_size=3,\n",
    "                        activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "                        kernel_regularizer=l2(hp.Choice('l2', [0.001, 0.0001])),\n",
    "                        input_shape=input_shape))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Dropout(hp.Float('dropout_1', 0.3, 0.5, step=0.1)))\n",
    "        \n",
    "        model.add(Conv1D(filters=hp.Int('filters_2', min_value=64, max_value=256, step=64),\n",
    "                        kernel_size=3,\n",
    "                        activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "                        kernel_regularizer=l2(hp.Choice('l2', [0.001, 0.0001]))))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(Dropout(hp.Float('dropout_2', 0.3, 0.5, step=0.1)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "                        activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "                        kernel_regularizer=l2(hp.Choice('l2', [0.001, 0.0001]))))\n",
    "        model.add(Dropout(hp.Float('dropout_3', 0.3, 0.5, step=0.1)))\n",
    "        \n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [8, 16, 32, 48]),\n",
    "            epochs=hp.Choice(\"epochs\", [10, 15, 20, 25, 30]),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 14m 12s]\n",
      "val_accuracy: 0.6078431606292725\n",
      "\n",
      "Best val_accuracy So Far: 0.6078431606292725\n",
      "Total elapsed time: 00h 14m 12s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |128               |filters_1\n",
      "relu              |tanh              |activation\n",
      "0.0001            |0.0001            |l2\n",
      "0.3               |0.3               |dropout_1\n",
      "64                |128               |filters_2\n",
      "0.5               |0.3               |dropout_2\n",
      "192               |64                |dense_units\n",
      "0.4               |0.3               |dropout_3\n",
      "adam              |rmsprop           |optimizer\n",
      "48                |8                 |batch_size\n",
      "10                |10                |epochs\n",
      "\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 20.2192 - accuracy: 0.3835 - val_loss: 1.3923 - val_accuracy: 0.5425\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 10s 164ms/step - loss: 1.2825 - accuracy: 0.4947 - val_loss: 1.2507 - val_accuracy: 0.5098\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 1.0289 - accuracy: 0.6481 - val_loss: 1.4338 - val_accuracy: 0.4379\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 0.7743 - accuracy: 0.7636 - val_loss: 1.6743 - val_accuracy: 0.4510\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 10s 161ms/step - loss: 0.6548 - accuracy: 0.8177 - val_loss: 1.8882 - val_accuracy: 0.4379\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 0.5671 - accuracy: 0.8486 - val_loss: 2.0593 - val_accuracy: 0.4706\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 0.5312 - accuracy: 0.8619 - val_loss: 2.3130 - val_accuracy: 0.4575\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 0.4595 - accuracy: 0.8967 - val_loss: 2.3374 - val_accuracy: 0.5033\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 0.4176 - accuracy: 0.9077 - val_loss: 2.3344 - val_accuracy: 0.5425\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 10s 164ms/step - loss: 0.4169 - accuracy: 0.9007 - val_loss: 2.4388 - val_accuracy: 0.5033\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 20.8026 - accuracy: 0.3546 - val_loss: 1.4833 - val_accuracy: 0.5621\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 1.2885 - accuracy: 0.4791 - val_loss: 1.2619 - val_accuracy: 0.5425\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 1.0603 - accuracy: 0.6248 - val_loss: 1.4014 - val_accuracy: 0.4379\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 0.8032 - accuracy: 0.7520 - val_loss: 1.5815 - val_accuracy: 0.4902\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 10s 162ms/step - loss: 0.6572 - accuracy: 0.8260 - val_loss: 1.8412 - val_accuracy: 0.4183\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 10s 160ms/step - loss: 0.5871 - accuracy: 0.8496 - val_loss: 2.0291 - val_accuracy: 0.4967\n",
      "Epoch 7/10\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.5403 - accuracy: 0.8660"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m      2\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mBayesianOptimization(\n\u001b[1;32m      3\u001b[0m     CNNHyperModel(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[1;32m      4\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_tuning\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     12\u001b[0m     X_train, y_train,\n\u001b[1;32m     13\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val)\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "Cell \u001b[0;32mIn[35], line 33\u001b[0m, in \u001b[0;36mCNNHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     35\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m48\u001b[39m]),\n\u001b[1;32m     36\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m30\u001b[39m]),\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     38\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "tuner = kt.BayesianOptimization(\n",
    "    CNNHyperModel(X_train.shape[1:]),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='cnn_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. \n",
      "Best parameters:\n",
      "Filters: 192 and 128\n",
      "Dense Units: 128\n",
      "Dropout: 0.4, 0.4, 0.3\n",
      "Regularization: 0.001\n",
      "Activation: tanh\n",
      "Batch Size: 48\n",
      "Epoch: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_batch_size = best_hps.get('batch_size')\n",
    "best_epoch = best_hps.get('epochs')\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "Best parameters:\n",
    "Filters: {best_hps.get('filters_1')} and {best_hps.get('filters_2')}\n",
    "Dense Units: {best_hps.get('dense_units')}\n",
    "Dropout: {best_hps.get('dropout_1')}, {best_hps.get('dropout_2')}, {best_hps.get('dropout_3')}\n",
    "Regularization: {best_hps.get('l2')}\n",
    "Activation: {best_hps.get('activation')}\n",
    "Batch Size: {best_batch_size}\n",
    "Epoch: {best_epoch}\n",
    "\"\"\")\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 2.1035 - accuracy: 0.3104 - val_loss: 1.7475 - val_accuracy: 0.4248\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.7085 - accuracy: 0.4157 - val_loss: 1.4796 - val_accuracy: 0.4379\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.5485 - accuracy: 0.4615 - val_loss: 1.2485 - val_accuracy: 0.5686\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.4347 - accuracy: 0.5033 - val_loss: 1.3857 - val_accuracy: 0.5425\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.3992 - accuracy: 0.4993 - val_loss: 1.3629 - val_accuracy: 0.5556\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.3649 - accuracy: 0.4927 - val_loss: 1.1786 - val_accuracy: 0.5882\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.3050 - accuracy: 0.5229 - val_loss: 1.2517 - val_accuracy: 0.5621\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.2965 - accuracy: 0.5282 - val_loss: 1.2368 - val_accuracy: 0.5817\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.2625 - accuracy: 0.5362 - val_loss: 1.1981 - val_accuracy: 0.5752\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.2746 - accuracy: 0.5236 - val_loss: 1.1332 - val_accuracy: 0.6209\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.2509 - accuracy: 0.5398 - val_loss: 1.1558 - val_accuracy: 0.6275\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.2337 - accuracy: 0.5422 - val_loss: 1.2212 - val_accuracy: 0.5621\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.2382 - accuracy: 0.5408 - val_loss: 1.1905 - val_accuracy: 0.6013\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 1.2048 - accuracy: 0.5432 - val_loss: 1.2139 - val_accuracy: 0.5425\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.2333 - accuracy: 0.5342 - val_loss: 1.1876 - val_accuracy: 0.5752\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.1830 - accuracy: 0.5498 - val_loss: 1.2147 - val_accuracy: 0.5621\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.2049 - accuracy: 0.5621 - val_loss: 1.1243 - val_accuracy: 0.6275\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.1997 - accuracy: 0.5521 - val_loss: 1.1455 - val_accuracy: 0.6340\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.1837 - accuracy: 0.5647 - val_loss: 1.1498 - val_accuracy: 0.6275\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.2058 - accuracy: 0.5581 - val_loss: 1.2505 - val_accuracy: 0.6078\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.1958 - accuracy: 0.5647 - val_loss: 1.2171 - val_accuracy: 0.6013\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.1759 - accuracy: 0.5790 - val_loss: 1.2653 - val_accuracy: 0.6078\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.1788 - accuracy: 0.6013 - val_loss: 1.1962 - val_accuracy: 0.5948\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.1601 - accuracy: 0.6036 - val_loss: 1.2659 - val_accuracy: 0.6013\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.0750 - accuracy: 0.6770 - val_loss: 1.2143 - val_accuracy: 0.5882\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.9575 - accuracy: 0.7703 - val_loss: 1.4025 - val_accuracy: 0.5817\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.8158 - accuracy: 0.8606 - val_loss: 1.3455 - val_accuracy: 0.6405\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.7205 - accuracy: 0.9050 - val_loss: 1.4320 - val_accuracy: 0.6405\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.7026 - accuracy: 0.9150 - val_loss: 1.4332 - val_accuracy: 0.6667\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.6387 - accuracy: 0.9409 - val_loss: 1.7243 - val_accuracy: 0.6078\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=best_epoch, batch_size=best_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First running without SMOTE\n",
    "    Epochs 20\n",
    "    batch size 32\n",
    "    Features Note Pitch and Chords (No Tempo)\n",
    "    Zero padding to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 1.5005 - accuracy: 0.6667 - 94ms/epoch - 19ms/step\n",
      "Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter search is complete. \n",
    "Parameters:\n",
    "Filters: 128 and 192\n",
    "Dense Units: 64\n",
    "Dropout: 0.3, 0.3, 0.4\n",
    "Regularization: 0.001\n",
    "Optimizer: adam\n",
    "Activation: relu\n",
    "Batch Size: 32\n",
    "Epoch: 25\n",
    "\n",
    "20/20 - 0s - loss: 0.9036 - accuracy: 0.6095 - 245ms/epoch - 12ms/step\n",
    "Test accuracy: 0.6094771027565002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then running with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter search is complete. \n",
    "Best parameters:\n",
    "Filters: 192 and 128\n",
    "Dense Units: 128\n",
    "Dropout: 0.4, 0.4, 0.3\n",
    "Regularization: 0.001\n",
    "Activation: tanh\n",
    "Batch Size: 48\n",
    "Epoch: 30\n",
    "\n",
    "\n",
    "5/5 - 0s - loss: 1.5005 - accuracy: 0.6667 - 94ms/epoch - 19ms/step\n",
    "Test accuracy: 0.6666666865348816"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
